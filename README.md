Tested with Python 3.12.
Local AI Assistant (LangChain + Ollama + FastAPI)

A fully local, free AI assistant built with LangChain, Ollama, and FastAPI, designed to demonstrate how real assistants should be built â€” without fragile agents, slow RAG pipelines, or paid APIs.

This project focuses on:

Correct intent routing

Clear tool boundaries

Predictable behavior

Fast local inference (CPU-friendly)

âœ¨ Features

âœ… Runs 100% locally (no OpenAI, no cloud)

âœ… Uses Ollama (e.g. llama3.2)

âœ… Clean intent map (no agent chaos)

âœ… Wikipedia lookup for factual entities

âœ… Reasoned answers for comparative questions

âœ… Conversation memory (session-based)

âœ… FastAPI backend with Swagger UI

âœ… CLI mode + API mode

âœ… Designed as a learning project

ğŸ§­ Why this project exists

Many LangChain tutorials jump straight into agents and RAG, which often leads to:

Infinite loops

Hallucinations

Dependency conflicts

Slow inference

Hard-to-debug behavior

This project takes a different approach:

Start with a robust assistant.
Add agents only when truly needed.

This mirrors how real production AI systems are designed.

ğŸ§  Architecture Overview
User
 â”œâ”€> Intent Router
 â”‚     â”œâ”€ time        â†’ deterministic tool
 â”‚     â”œâ”€ entity      â†’ Wikipedia
 â”‚     â”œâ”€ comparison  â†’ constrained LLM reasoning
 â”‚     â””â”€ open        â†’ LLM + memory
 â”‚
 â””â”€> Response


No agent loops.
No uncontrolled tool calls.
Everything is explicit.

ğŸ§© Intent Map
Intent	Description	Example
time	Date/time queries	â€œWhat time is it?â€
entity	Encyclopedic lookup	â€œWho is Alan Turing?â€
comparison	Reasoned factual questions	â€œWarmest country in Europe?â€
open	Conversational / explanatory	â€œExplain black holesâ€

ğŸš€ Getting Started
1ï¸âƒ£ Create environment
conda create -n langchain_agent python=3.12
conda activate langchain_agent

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Start Ollama
ollama serve
ollama pull llama3.2

ğŸ’¬ Run in CLI mode
python assistant.py


Example:

You: What are the warmest countries in Europe?
ğŸ¤– Cyprus, Greece, and southern Spain are generally considered the warmest...

ğŸŒ Run as a Local API
python api.py


Open in browser:

http://127.0.0.1:8000/docs


Test via Swagger UI.

ğŸ“¡ API Example
Request
{
  "message": "Who is Ada Lovelace?",
  "session_id": "student1"
}

Response
{
  "reply": "ğŸ“š Source: Wikipedia\n\nAda Lovelace was an English mathematician..."
}

ğŸ§  Memory Model

Session-based memory using session_id

Stored in-process (simple, fast, transparent)

Designed for learning â€” not production persistence

âŒ What this project does NOT do (by design)

âŒ No autonomous agents

âŒ No uncontrolled tool loops

âŒ No heavy RAG pipelines

âŒ No paid APIs

âŒ No embeddings by default

These are intentional tradeoffs for clarity and reliability.

ğŸ”„ Assistant vs Agent (Important)
Assistant	Agent
Explicit routing	Autonomous planning
Predictable	Hard to debug
Fast	Often slow
Beginner-friendly	Easy to misuse
Production-aligned	Demo-oriented

This project proves you can build useful AI systems without agents.

ğŸ“š Learning Outcomes

By studying this repo, you will learn:

How intent routing works

When not to use RAG

Why agents often fail beginners

How real assistants are structured

How to combine tools + LLM safely

ğŸ› ï¸ Future Extensions (Optional)

Lightweight retrieval (hybrid RAG-lite)

Source attribution per answer

Persistent memory (SQLite / Redis)

Agent comparison demo

Frontend UI

ğŸ‘¨â€ğŸ“ Project Context

Built as a student learning project, inspired by experimentation with:

LangChain

Ollama

FastAPI

Modern AI engineering practices

ğŸ“œ License

MIT â€” use freely, learn freely.
